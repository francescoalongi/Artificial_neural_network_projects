{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook used for the creation the Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the function used to split the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def valid_create(trainJsonPath, validJsonPath='./valid_data.json', valRatio=0.1, seed=1234):\n",
    "    if valRatio > 1:\n",
    "        raise Exception('The validation ratio must be <= 1.')\n",
    "\n",
    "    with open(trainJsonPath, 'r') as trainJson:\n",
    "        data_json = json.load(trainJson)\n",
    "        trainJson.close()\n",
    "\n",
    "    image_filenames_train = list(set([element['image_filename'] for element in data_json.get('questions')]))\n",
    "    nTrainImg = len(image_filenames_train)\n",
    "    data_valid = {'questions': []}\n",
    "    data_train = {'questions': []}\n",
    "    image_filenames_valid = []\n",
    "    random.seed(seed)\n",
    "\n",
    "    for i in range(int(valRatio * nTrainImg)):\n",
    "        chosenFile = random.choice(image_filenames_train)\n",
    "        image_filenames_valid.append(chosenFile)\n",
    "        image_filenames_train.remove(chosenFile)\n",
    "\n",
    "    for el in data_json.get('questions'):\n",
    "        if el.get('image_filename') in image_filenames_valid:\n",
    "            data_valid.get('questions').insert(-1, el)\n",
    "        else:\n",
    "            data_train.get('questions').insert(-1, el)\n",
    "\n",
    "    random.shuffle(data_train.get('questions'))\n",
    "    random.shuffle(data_valid.get('questions'))\n",
    "\n",
    "    kaggle = False\n",
    "    if kaggle: trainJsonPath = 'train_data.json'\n",
    "\n",
    "    with open(trainJsonPath, 'w') as trainJson, open(validJsonPath, 'w') as validJson:\n",
    "        json.dump(data_train, trainJson)\n",
    "        json.dump(data_valid, validJson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of all the ausiliar variables and call of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "datasetName = '../input/ann-and-dl-vqa/dataset_vqa'\n",
    "\n",
    "trainJsonName = 'train_data.json'\n",
    "validJsonName = 'valid_data.json'\n",
    "\n",
    "trainJsonPath = os.path.join(cwd, datasetName, trainJsonName)\n",
    "\n",
    "valid_create(trainJsonPath, validJsonName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [profile===thesis]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
