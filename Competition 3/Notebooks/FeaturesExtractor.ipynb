{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encodings creation notebook\n",
    "This notebook was used to get the encodings of the images using a VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import json, os\n",
    "import random\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading dataset json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h = 224\n",
    "img_w = 224\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "datasetName = '../input/ann-and-dl-vqa/dataset_vqa'\n",
    "jsonFiles = '../input/json-files'\n",
    "trainJsonName = 'train_data.json'\n",
    "validJsonName = 'valid_data.json'\n",
    "imagesPath = os.path.join(datasetName, 'train')\n",
    "trainJsonPath = os.path.join(jsonFiles, trainJsonName)\n",
    "validJsonPath = os.path.join(jsonFiles, validJsonName)\n",
    "\n",
    "with open(trainJsonPath,'r') as json_file_train, open (validJsonPath, 'r') as json_file_valid:\n",
    "    data_train = json.load(json_file_train).get('questions')\n",
    "    data_valid = json.load(json_file_valid).get('questions')\n",
    "    json_file_train.close()\n",
    "    json_file_valid.close()\n",
    "    \n",
    "print(data_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating the encoder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = tf.keras.applications.VGG19(include_top = False, pooling = 'avg', input_shape = (img_h,img_w,3), weights = 'imagenet')\n",
    "for l in fe.layers:\n",
    "    l.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(fe)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the encoding of the training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = set([el['image_filename'] for el in data_train])\n",
    "valid_images = set([el['image_filename'] for el in data_valid])\n",
    "len_train = len(train_images)\n",
    "len_valid = len(valid_images)\n",
    "print('taken the ' + str(len(valid_images)/len(train_images))+' of validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor_map = {}\n",
    "i = 0\n",
    "for imagename in train_images:\n",
    "    print('{:3.2f} %'.format(i/len_train * 100), end = '\\r')\n",
    "    image = Image.open(os.path.join(imagesPath, imagename)).resize((img_w, img_h)).convert('RGB')\n",
    "    img = np.array(image).astype(np.float32) / 255\n",
    "    res = model.predict(x = np.expand_dims(img,0))\n",
    "    train_tensor_map[str(imagename)] = res.tolist()\n",
    "    i = i + 1\n",
    "\n",
    "json.dump(train_tensor_map, open(\"train_tensors_VGG19_GAP.json\",\"w\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tensor_map = {}\n",
    "i = 0\n",
    "for imagename in valid_images:\n",
    "    print('{:3.2f} %'.format(i/len_valid * 100), end = '\\r')\n",
    "    image = Image.open(os.path.join(imagesPath, imagename)).resize((img_w, img_h)).convert('RGB')\n",
    "    img = np.array(image).astype(np.float32) / 255\n",
    "    res = model.predict(x = np.expand_dims(img,0))\n",
    "    valid_tensor_map[str(imagename)] = res.tolist()\n",
    "    i = i + 1\n",
    "    \n",
    "json.dump(valid_tensor_map, open(\"valid_tensors_VGG19_GAP.json\",\"w\"), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the encoding of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testJsonName = 'test_data.json'\n",
    "imagesPathTest = os.path.join(datasetName,'test')\n",
    "testJsonPath = os.path.join(datasetName, testJsonName)\n",
    "\n",
    "with open (testJsonPath, 'r') as json_file_test:\n",
    "    data_test = json.load(json_file_test).get('questions')\n",
    "    json_file_test.close()\n",
    "    \n",
    "test_images = set([el['image_filename'] for el in data_test])\n",
    "\n",
    "len_test = len(test_images)\n",
    "\n",
    "test_tensor_map = {}\n",
    "i = 0\n",
    "for imagename in test_images:\n",
    "    print('{:3.2f} %'.format(i/len_test * 100),end = '\\r')\n",
    "    image = Image.open(os.path.join(imagesPathTest, imagename)).resize((img_w, img_h)).convert('RGB')\n",
    "    img = np.array(image).astype(np.float32) / 255\n",
    "    res = model.predict(x = np.expand_dims(img,0))\n",
    "    test_tensor_map[str(imagename)] = res.tolist()\n",
    "    i = i + 1\n",
    "\n",
    "json.dump(test_tensor_map, open(\"test_tensors_VGG19_GAP.json\",\"w\"), indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [profile===thesis]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
